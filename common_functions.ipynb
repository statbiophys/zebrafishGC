{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584d0686",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GC_sig(GC, Fstat, threshold_F):\n",
    "    \"\"\" \n",
    "    Get the significant links among all pairs.\n",
    "    \n",
    "    :params GC: Granger causality matrix of all pairs (NxN)\n",
    "    :params Fstat: F-statistics of all pairs (NxN)\n",
    "    :params threshold_F: threshold of significance. Can be a single value (int)\n",
    "                         or a matrix (NxN) for customized threshold for each pair\n",
    "    \n",
    "    GC[i,j] is significant if Fstat[i,j] > threshold_F or Fstat[i,j] > threshold_F[i,j]\n",
    "    \n",
    "    \"\"\"\n",
    "    mask = Fstat > threshold_F\n",
    "    GC_sig = GC.copy()\n",
    "    GC_sig[~mask] = 0\n",
    "    return GC_sig\n",
    "\n",
    "\n",
    "def get_mean_GC(gc):\n",
    "    \"\"\"\n",
    "    Get the mean value of Granger causality values.\n",
    "    Can be calculate on GC or GC_sig. \n",
    "    \n",
    "    :params gc: Granger causality matrix of all pairs (NxN)\n",
    "    \n",
    "    \"\"\"\n",
    "    n_cells = len(gc)\n",
    "    gc[gc==0] = np.nan\n",
    "    return np.nanmean(gc)\n",
    "\n",
    "\n",
    "def get_percent_sig(gc_sig):\n",
    "    \"\"\"\n",
    "    Get percentage of significant Granger causality links.\n",
    "    \n",
    "    :params gc_sig: significant Granger causality matrix of all pairs (NxN)\n",
    "    \n",
    "    \"\"\"\n",
    "    n_cells = len(gc_sig)\n",
    "    gc_sig[gc_sig==0] = np.nan\n",
    "    n_sig = len([i  for j in gc_sig for i in j if i>0]) \n",
    "    p_sig = n_sig / (n_cells * (n_cells-1))\n",
    "    return p_sig\n",
    "\n",
    "\n",
    "\n",
    "# ratio functions (motoneuron dataset)\n",
    "    \n",
    "# get ratio from df\n",
    "def get_ratio(df, loc, sig=True, gc_type='dff', ratio_type='ipsi'):\n",
    "    \"\"\" Return either ipsi ratio or RC ratio, for all links or significant links only.\n",
    "    Can choose on which GC matrix the ratio is calculated (default: dff).\n",
    "    \n",
    "    Ipsi-lateral ratio: \n",
    "    number of ipsi-lateral links / (number of ipsi-lateral links + number of contra-lateral links)\n",
    "    \n",
    "    Rostro-caudal ratio:\n",
    "    number of rostral-to-caudal links / (number of rostral-to-caudal links + number of caudal-to-rostral links)\n",
    "    \n",
    "    Function specific to how the dataframe is built. For generic ratio calculation use:\n",
    "        get_ratio_from_GC\n",
    "    where only GC matrix and middle index are necessary.\n",
    "    \n",
    "    :params df: motoneuron dataframe with fish/trials as index (pandas DataFrame)\n",
    "    :params loc: index of fish/trial to calculate the ratio for (int)\n",
    "    :params sig: to calculate the ratio on significant links only or on all links (bool)\n",
    "    :params gc_type: type of fluorescence trace used to calculate GC (string)\n",
    "    :params ratio_type: ipsi-lateral or rostrocaudal (string)\n",
    "    \n",
    "    \"\"\"\n",
    "    fish = df.loc[loc].Fish\n",
    "    trace = df.loc[loc].Trace\n",
    "    mid = int(df.loc[loc].mid)\n",
    "    \n",
    "    if sig:  # Get ratio for significant links.\n",
    "        if gc_type == 'raw':\n",
    "            gc = df.loc[loc].GC_sig_raw\n",
    "        elif gc_type == 'dt':\n",
    "            gc = df.loc[loc].GC_sig_dt\n",
    "        elif gc_type == 'f_smooth':\n",
    "            gc = df.loc[loc].GC_sig_f_smooth\n",
    "        elif gc_type == 'dfdt_smooth':\n",
    "            gc = df.loc[loc].GC_sig_dfdt_smooth\n",
    "        elif gc_type == 'disc_f':\n",
    "            gc = df.loc[loc].GC_sig_disc_f\n",
    "        else:\n",
    "            if gc_type != 'dff':\n",
    "                print('Unknown \\'gc_type\\' param: GC on DF/F is returned.')\n",
    "            gc = df.loc[loc].GC_sig\n",
    "        \n",
    "    else:  # Get ratio for all links\n",
    "        if gc_type == 'raw':\n",
    "            gc = df.loc[loc].GC_raw\n",
    "        elif gc_type == 'dt':\n",
    "            gc = df.loc[loc].GC_dt\n",
    "        elif gc_type == 'f_smooth':\n",
    "            gc = df.loc[loc].GC_f_smooth\n",
    "        elif gc_type == 'dfdt_smooth':\n",
    "            gc = df.loc[loc].GC_dfdt_smooth\n",
    "        elif gc_type == 'disc_f':\n",
    "            gc = df.loc[loc].GC_disc_f\n",
    "        else:\n",
    "            if gc_type != 'dff':\n",
    "                print('Unknown \\'gc_type\\' param: GC on DF/F is returned.')\n",
    "            gc = df.loc[loc].GC\n",
    "    \n",
    "    \n",
    "    return get_ratio_from_GC(gc, mid, ratio_type)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# get ratio from GC matrix\n",
    "def get_ratio_from_GC(gc, mid, ratio_type='ipsi'):\n",
    "    \"\"\" Return either ipsi ratio or RC ratio, for all links or significant links only.\n",
    "    GC matrix in param.\n",
    "    \n",
    "    Ipsi-lateral ratio: \n",
    "    number of ipsi-lateral links / (number of ipsi-lateral links + number of contra-lateral links)\n",
    "    \n",
    "    Rostro-caudal ratio:\n",
    "    number of rostral-to-caudal links / (number of rostral-to-caudal links + number of caudal-to-rostral links)\n",
    "    \n",
    "    Function specific to how the dataframe is built. For generic ratio calculation use:\n",
    "        get_ratio_from_GC\n",
    "    where only GC matrix and middle index are necessary.\n",
    "    \n",
    "    :params gc: Granger causality matrix, significant or not (NxN)\n",
    "    :params mid: index of neuron separating left-right side (int). Note: neurons must be organized from\n",
    "                 top left --> bottom left --> top right --> bottom right.\n",
    "    :params ratio_type: ipsi-lateral or rostrocaudal (string)\n",
    "    \"\"\"\n",
    "    \n",
    "    gc_ipsi_left = gc[:mid, :mid]\n",
    "    gc_ipsi_right = gc[mid:, mid:]\n",
    "    \n",
    "    if ratio_type == 'RC':\n",
    "        gc_RC_left = gc_ipsi_left[np.triu_indices(len(gc_ipsi_left), k=1)]\n",
    "        gc_CR_left = gc_ipsi_left[np.tril_indices(len(gc_ipsi_left), k=-1)]\n",
    "        gc_RC_right = gc_ipsi_right[np.triu_indices(len(gc_ipsi_right), k=1)]\n",
    "        gc_CR_right = gc_ipsi_right[np.tril_indices(len(gc_ipsi_right), k=-1)]\n",
    "\n",
    "        num_RC_left = len(gc_RC_left[gc_RC_left>0])\n",
    "        num_CR_left = len(gc_CR_left[gc_CR_left>0])\n",
    "        num_RC_right = len(gc_RC_right[gc_RC_right>0]) \n",
    "        num_CR_right = len(gc_CR_right[gc_CR_right>0]) \n",
    "\n",
    "        strength_RC_left = np.nansum(gc_RC_left)\n",
    "        strength_CR_left = np.nansum(gc_CR_left)\n",
    "        strength_RC_right = np.nansum(gc_RC_right)\n",
    "        strength_CR_right = np.nansum(gc_CR_right)\n",
    "\n",
    "        RC_number = num_RC_left + num_RC_right\n",
    "        CR_number = num_CR_left + num_CR_right\n",
    "        RC_strength = strength_RC_left + strength_RC_right\n",
    "        CR_strength = strength_CR_left + strength_CR_right\n",
    "\n",
    "        if RC_number == 0 and CR_number == 0:\n",
    "            print(\"No links.\")\n",
    "            return np.nan, np.nan, np.nan\n",
    "        else:\n",
    "            if RC_number == 0:\n",
    "                print(\"No R-->C links.\")\n",
    "                RC_mean_strength = 0\n",
    "            else:\n",
    "                RC_mean_strength = RC_strength / RC_number\n",
    "                \n",
    "            if CR_number == 0:\n",
    "                print(\"No C-->R links.\")\n",
    "                CR_mean_strength = 0\n",
    "            else:\n",
    "                CR_mean_strength = CR_strength / CR_number\n",
    "            \n",
    "            ratio = RC_mean_strength / (RC_mean_strength + CR_mean_strength)\n",
    "            return ratio\n",
    "    \n",
    "    else:\n",
    "        if ratio_type != 'ipsi':\n",
    "            print('Unknown \\'ratio_type\\' param: ipsi ratio is returned.')\n",
    "        \n",
    "        num_ipsi_left = len(gc_ipsi_left[gc_ipsi_left>0])\n",
    "        num_ipsi_right = len(gc_ipsi_right[gc_ipsi_right>0]) \n",
    "        strength_ipsi_left = np.nansum(gc_ipsi_left)\n",
    "        strength_ipsi_right = np.nansum(gc_ipsi_right)\n",
    "\n",
    "        ipsi_number = num_ipsi_left + num_ipsi_right\n",
    "        ipsi_strength = strength_ipsi_left + strength_ipsi_right\n",
    "\n",
    "        gc_contra_from_left = gc[:mid, mid:]\n",
    "        gc_contra_from_right = gc[mid:, :mid]\n",
    "        num_contra_from_left = len(gc_contra_from_left[gc_contra_from_left>0])\n",
    "        num_contra_from_right = len(gc_contra_from_right[gc_contra_from_right>0]) \n",
    "        strength_contra_from_left = np.nansum(gc_contra_from_left)\n",
    "        strength_contra_from_right = np.nansum(gc_contra_from_right)\n",
    "\n",
    "        contra_number = num_contra_from_left + num_contra_from_right\n",
    "        contra_strength = strength_contra_from_left + strength_contra_from_right\n",
    "\n",
    "        if ipsi_number == 0 and contra_number == 0:\n",
    "            print(\"No links.\")\n",
    "            return np.nan, np.nan, np.nan\n",
    "        else:\n",
    "            if ipsi_number == 0:\n",
    "                print(\"No ipsi links.\")\n",
    "                ipsi_mean_strength = 0\n",
    "            else:\n",
    "                ipsi_mean_strength = ipsi_strength / ipsi_number\n",
    "\n",
    "            if contra_number == 0:\n",
    "                print(\"No contra links.\")\n",
    "                contra_mean_strength = 0\n",
    "            else:\n",
    "                contra_mean_strength = contra_strength / contra_number\n",
    "\n",
    "            ratio = ipsi_mean_strength / (ipsi_mean_strength + contra_mean_strength)\n",
    "            return ratio\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5663cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_GC_from_Fstat(Fstat, dof_full, dof_reduced, t_regr=1653):\n",
    "    \"\"\" \n",
    "    Calulate GC matrix from F-statistics value of one pair or one matrix of NxN pairs.\n",
    "    \n",
    "    :params Fstat: F-statistics of each pair (int or NxN)\n",
    "    :params dof_full: number of degrees of freedom of the full model (n_rois*n_lags)\n",
    "    :params dof_reduced: number of degrees of freedom of the reduced model ( (n_rois-1)*n_lags )\n",
    "    :params t_regr: number of timesteps used for GC (n_timesteps - n_lags)\n",
    "    \"\"\"\n",
    "    # For hindbrain:\n",
    "    #     t_ regr = n_timesteps - n_lags = 1653 because 1656 timesteps taken not 1744\n",
    "    #     BVGC\n",
    "    #         dof_full = 2 * n_lags = 6\n",
    "    #         dof_reduced = n_lags = 3\n",
    "    #     cBVGC\n",
    "    #         dof_full = 3 * n_lags = 9\n",
    "    #         dof_reduced = 2 * n_lags = 6\n",
    "    #     MVGC\n",
    "    #         dof_full = n_rois * n_lags = 60\n",
    "    #         dof_reduced = (n_rois - 1) * n_lags = 57\n",
    "    #     cMVGC\n",
    "    #         dof_full =  (n_rois + 1) * n_lags = 63\n",
    "    #         dof_reduced = n_rois * n_lags = 60\n",
    "    return np.log((Fstat * (dof_full - dof_reduced) / (t_regr - dof_full) + 1) * (t_regr - dof_full) / (t_regr - dof_reduced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c708f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_signal(neuron_signal, t_cycles):\n",
    "    \"\"\"\n",
    "    Shuffle calcium signal keeping the stimulus structure.\n",
    "    for hindbrain data: \n",
    "        t_cycles = np.array([round(5.81*(5+i*15)) for i in range(20)])\n",
    "    \n",
    "    :params neuron_signal: calcium trace to shuffle\n",
    "    :params t_cycle: start times of stimulus cycles.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx_t_cycles = [i for i in range(len(t_cycles)-1)]\n",
    "    subset = sample(idx_t_cycles, len(t_cycles)-1)\n",
    "\n",
    "    signal_shuffled = np.zeros((t_cycles[-1] - t_cycles[0]))\n",
    "    start = 0\n",
    "\n",
    "    for idx in subset:\n",
    "        cycle = neuron_signal[t_cycles[subset[idx]]:t_cycles[subset[idx]+1]]\n",
    "        end = start + len(cycle)\n",
    "        signal_shuffled[start:end] = cycle\n",
    "        start = end\n",
    "    \n",
    "    return signal_shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7925dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bvgc(signal1, signal2, n_lags=3, pval=0.01, tau=1, verbose=False):\n",
    "    # single BVGC value from neuron 1 to neuron 2\n",
    "    (n_rois, n_timesteps) = (2, len(signal1))\n",
    "    threshold_F = stats.f.ppf(1 - pval, n_lags, n_timesteps - 3 * n_lags - 1) \n",
    "    \n",
    "    x_lagged = lag_signals([signal1], n_lags + 1, tau=1)[0]  # n_lags+1 --> n_lags + present\n",
    "    y_lagged = lag_signals([signal2], n_lags + 1, tau=1)[0]\n",
    "\n",
    "    x_past = x_lagged[:, :-1]  # past of signal x (lagged)\n",
    "\n",
    "    y_present = np.expand_dims(y_lagged[:, -1], axis=1)  # current value of signal y (lagged)\n",
    "    y_past = y_lagged[:, :-1]  # past of signal y (lagged)\n",
    "    xy_past = np.concatenate((x_past, y_past), axis=1)  # both past concatenated\n",
    "\n",
    "    reduced_model = np.concatenate((y_past, y_present), axis=1)  # y's past and current value\n",
    "    full_model = np.concatenate((xy_past, y_present), axis=1)  # x and y's past and current y value\n",
    "\n",
    "    # Covariances\n",
    "    entr_reduced = entr(reduced_model.T) - entr(y_past.T)\n",
    "    entr_full = entr(full_model.T) - entr(xy_past.T)\n",
    "\n",
    "    # residual sum of squares\n",
    "    RSS_reduced = np.exp(entr_reduced) # (n_timesteps -  n_lags) * sigma_reduced\n",
    "    RSS_full = np.exp(entr_full) # (n_timesteps - 2 * n_lags) * sigma_full\n",
    "\n",
    "    sigma_reduced = RSS_reduced / (n_timesteps - n_lags)\n",
    "    sigma_full = RSS_full / (n_timesteps - 2 * n_lags) \n",
    "\n",
    "    GC = math.log(sigma_reduced / sigma_full) # GC value\n",
    "    Fstat = (n_timesteps - 3 * n_lags - 1) / n_lags * (RSS_reduced - RSS_full) / RSS_full\n",
    "\n",
    "    if Fstat > threshold_F:\n",
    "        GC_sig = GC\n",
    "    else:\n",
    "        GC_sig = 0\n",
    "\n",
    "    if verbose:\n",
    "        print(\"F statistics:\", Fstat)\n",
    "        print(\"F threshold:\", threshold_F)\n",
    "        print(\"Significant GC values:\", GC)\n",
    "\n",
    "    return GC_sig, GC, Fstat, threshold_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f84ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbvgc(signal1, signal2, signal3, n_lags=3, pval=0.01, tau=1, verbose=False):\n",
    "    # single cBVGC value from neuron 1 to neuron 2 conditioned on signal3 = stimulus\n",
    "    (n_rois, n_timesteps) = (3, len(signal1))\n",
    "    threshold_F = stats.f.ppf(1 - pval, n_lags, n_timesteps - (n_rois+1) * n_lags - 1) \n",
    "   \n",
    "    x_lagged = lag_signals([signal1], n_lags + 1, tau=1)[0]  # n_lags+1 --> n_lags + present\n",
    "    y_lagged = lag_signals([signal2], n_lags + 1, tau=1)[0]\n",
    "    z_lagged = lag_signals([signal3], n_lags + 1, tau=1)[0]\n",
    "    \n",
    "    x_past = x_lagged[:, :-1]  # past of signal x (lagged)\n",
    "\n",
    "    y_present = np.expand_dims(y_lagged[:, -1], axis=1)  # current value of signal y (lagged)\n",
    "    y_past = y_lagged[:, :-1]  # past of signal y (lagged)\n",
    "    z_past = z_lagged[:, :-1] \n",
    "    \n",
    "       \n",
    "    yz_past = np.concatenate((y_past, z_past), axis=1)  # past without x\n",
    "    xyz_past = np.concatenate((x_past, yz_past), axis=1)  # all past\n",
    "    \n",
    "    reduced_model = np.concatenate((y_present, yz_past), axis=1)  # past without x and current y value\n",
    "    full_model = np.concatenate((xyz_past, y_present), axis=1)  # x, y, z's past and current y value\n",
    "        \n",
    "    # Covariances\n",
    "    entr_reduced = entr(reduced_model.T) - entr(yz_past.T)\n",
    "    entr_full = entr(full_model.T) - entr(xyz_past.T)\n",
    "\n",
    "    # residual sum of squares\n",
    "    RSS_reduced = np.exp(entr_reduced) # (n_timesteps -  n_lags) * sigma_reduced\n",
    "    RSS_full = np.exp(entr_full) # (n_timesteps - 2 * n_lags) * sigma_full\n",
    "\n",
    "    sigma_reduced = RSS_reduced / (n_timesteps - (n_rois - 1) * n_lags)\n",
    "    sigma_full = RSS_full / (n_timesteps - n_rois * n_lags) \n",
    "\n",
    "    GC = math.log(sigma_reduced / sigma_full) # GC value\n",
    "    Fstat = (n_timesteps - (n_rois+1) * n_lags - 1) / n_lags * (RSS_reduced - RSS_full) / RSS_full\n",
    "\n",
    "    if Fstat > threshold_F:\n",
    "        GC_sig = GC\n",
    "    else:\n",
    "        GC_sig = 0\n",
    "\n",
    "    if verbose:\n",
    "        print(\"F statistics:\", Fstat)\n",
    "        print(\"F threshold:\", threshold_F)\n",
    "        print(\"Significant GC values:\", GC)\n",
    "\n",
    "    return GC_sig, GC, Fstat, threshold_F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfb921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mvgc(signal1, signal2, Z, n_lags=3, pval=0.01, tau=1, verbose=False):\n",
    "    # single MVGC value from neuron 1 to neuron 2 conditioned on Z = all other neurons \n",
    "    # (Z can also include stimulus for cMVGC)\n",
    "    (n_rois, n_timesteps) = (2+len(Z), len(signal1))\n",
    "\n",
    "    threshold_F = stats.f.ppf(1 - pval, n_lags, n_timesteps - (n_rois+1) * n_lags - 1)  # statistical threshold \n",
    "\n",
    "    x_lagged = lag_signals([signal1], n_lags + 1, tau=1)[0]  # n_lags+1 --> n_lags + present\n",
    "    y_lagged = lag_signals([signal2], n_lags + 1, tau=1)[0]\n",
    "    z_lagged = lag_signals(Z, n_lags + 1, tau=1)\n",
    "    \n",
    "    \n",
    "    x_past = x_lagged[:, :-1]  # past of signal x (lagged)\n",
    "\n",
    "    y_present = np.expand_dims(y_lagged[:, -1], axis=1)  # current value of signal y (lagged)\n",
    "    y_past = y_lagged[:, :-1]  # past of signal y (lagged)\n",
    "    z_past = np.concatenate(z_lagged[:, :, :-1], axis=1)\n",
    "            \n",
    "    yz_past = np.concatenate((y_past, z_past), axis=1)  # past without x\n",
    "    xyz_past = np.concatenate((x_past, yz_past), axis=1)  # all past\n",
    "    \n",
    "    reduced_model = np.concatenate((y_present, yz_past), axis=1)  # past without x and current y value\n",
    "    full_model = np.concatenate((xyz_past, y_present), axis=1)  # x, y, z's past and current y value\n",
    "        \n",
    "    # Covariances\n",
    "    entr_reduced = entr(reduced_model.T) - entr(yz_past.T)\n",
    "    entr_full = entr(full_model.T) - entr(xyz_past.T)\n",
    "\n",
    "    # residual sum of squares\n",
    "    RSS_reduced = np.exp(entr_reduced) # (n_timesteps -  n_lags) * sigma_reduced\n",
    "    RSS_full = np.exp(entr_full) # (n_timesteps - 2 * n_lags) * sigma_full\n",
    "\n",
    "    sigma_reduced = RSS_reduced / (n_timesteps - (n_rois - 1) * n_lags)\n",
    "    sigma_full = RSS_full / (n_timesteps - n_rois * n_lags) \n",
    "\n",
    "    GC = math.log(sigma_reduced / sigma_full) # GC value\n",
    "    Fstat = (n_timesteps - (n_rois+1) * n_lags - 1) / n_lags * (RSS_reduced - RSS_full) / RSS_full\n",
    "\n",
    "    if Fstat > threshold_F:\n",
    "        GC_sig = GC\n",
    "    else:\n",
    "        GC_sig = 0\n",
    "\n",
    "    if verbose:\n",
    "        print(\"F statistics:\", Fstat)\n",
    "        print(\"F threshold:\", threshold_F)\n",
    "        print(\"Significant GC values:\", GC)\n",
    "\n",
    "    return GC_sig, GC, Fstat, threshold_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bad927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionedLinearCausalityTE(signals, Z, multi=False, n_lags=3, pval=0.01, tau=1, verbose=False):\n",
    "    # signals should not be in Z: for multi + tail angle regressor --> all neurons in signals, ta_reg in Z\n",
    "    \n",
    "    \"\"\" Calculate the Granger causality between each pair of signals, conditioned on the signals in Z.\n",
    "    cov([...]) --> symmetric square matrix (cov between each pair of elements)\n",
    "    determinant of cov = generalized variance: measure of multi-dimensional scatter (scalar value) / linked to\n",
    "    differential entropy -->  the determinant is nonzero if and only if the matrix  is invertible, and the linear map\n",
    "    represented by the matrix is an isomorphism. det is zero if and only if the column vectors (or the row vectors) of\n",
    "    the matrix are linearly dependent.\n",
    "    see slide 32 of GC presentation\n",
    "    Fstat ~ F(n_lags, n_timesteps - 2*n_lags)\n",
    "\n",
    "    Numpy cov input matrix: each row of m represents a variable, and each column a single observation\n",
    "    Matlab cov input matrix: each row is an observation, and each column a variable\n",
    "\n",
    "    :param signals: variables in rows and observations in columns --> shape = n_rois x n_timesteps (/!\\ Matlab opposite)\n",
    "    :param n_lags: number of past time steps to include in model (order)\n",
    "    :param pval: significance level for the F test. The lower it is, the higher threshold_F (does not change GC)\n",
    "    :param tau: number of time steps between lags --> keep past values at times: [t-tau*i for i in range(n_lags)]\n",
    "           (tau=1 for GC: keep all values up to n_lags, don't skip any)\n",
    "    :param verbose: set to True to display result and threshold\n",
    "\n",
    "    :return GC_sig: significant values of Granger causality matrix\n",
    "    :return GC: Granger causality matrix\n",
    "    :return F_stat: F statistics of the GC test\n",
    "    :return threshold_F: threshold for significance.\n",
    "    \"\"\"\n",
    "    (n_rois, n_timesteps) = signals.shape\n",
    "    n_pairs = n_rois * (n_rois-1)\n",
    "    \n",
    "    if multi:\n",
    "        n_dof = n_rois\n",
    "    else:\n",
    "        n_dof = 2\n",
    "\n",
    "    threshold_F = stats.f.ppf(1 - pval / n_pairs, n_lags, n_timesteps - (n_dof + len(Z) + 1) * n_lags - 1) # len(Z) + 1\n",
    "    \n",
    "    # Bonferroni corrected 1 - pval/n_pairs instead of 1 - pval: n_pairs = number of hypotheses tested,\n",
    "    # pval = significance level\n",
    "\n",
    "    # In stattools gc:\n",
    "    # threshold_F = stats.f.sf\n",
    "    # cdf(F-function, dfn, dfd): Cumulative distribution function. proba that the variable is LESS than or equal to x\n",
    "    # sf(F-function, dfn, dfd): Survival function (also defined as 1 - cdf, but sf is sometimes more accurate). also\n",
    "    # called reliability function --> probability that the variate takes a value GREATER than x\n",
    "    # ppf(desired pval, dfn, dfd): Percent point function (inverse of cdf -> percentiles) --> for a distribution\n",
    "    # function we calculate the probability that the variable is LESS than or equal to x for a given x\n",
    "\n",
    "    # signals = signal.detrend(signals)  # removes the linear trend from each signal: makes the data stationary\n",
    "    # signals = normalisa(signals)  # Matlab normalisa: mean=0, std=1 for each ROI\n",
    "    # normalization is useless: it does not change GC nor Fstat results\n",
    "    # detrend --> slightly different GC & Fstat\n",
    "\n",
    "    Fstat = np.zeros((n_rois, n_rois))  # matrix of all F_xy\n",
    "    GC = np.zeros((n_rois, n_rois))  # matrix of all GC_xy\n",
    "    GC_sig = np.zeros((n_rois, n_rois))  # matrix of all significant GC_xy (if F_xy >= threshold_F)\n",
    "\n",
    "    signals_lagged = lag_signals(signals, n_lags + 1, tau)  # shape: n_rois, n_timesteps-tau*(n_lags-1), n_lags\n",
    "    z_lagged = lag_signals(Z, n_lags + 1, tau)\n",
    "    \n",
    "    for i, x in enumerate(signals):  # for each column (each roi)\n",
    "        x_lagged = signals_lagged[i]\n",
    "        x_past = x_lagged[:, :-1]  # past of signal x (lagged)\n",
    "        \n",
    "        for j, y in enumerate(signals):\n",
    "            if i != j:\n",
    "                y_lagged = signals_lagged[j]\n",
    "                y_present = np.expand_dims(y_lagged[:, -1], axis=1)  # current value of signal y (lagged)\n",
    "                y_past = y_lagged[:, :-1]  # past of signal y (lagged)\n",
    "\n",
    "                z_past = np.concatenate(z_lagged[:, :, :-1], axis=1)\n",
    "                print(z_lagged.shape)\n",
    "                \n",
    "                if multi:\n",
    "                    small = min(i, j)\n",
    "                    large = max(i, j)\n",
    "                    zmulti_indices = np.r_[0:small, small + 1:large, large + 1:n_rois]\n",
    "                    zmulti_lagged = signals_lagged[zmulti_indices]\n",
    "                    zmulti_past = np.concatenate(zmulti_lagged[:, :, :-1], axis=1)\n",
    "                    z_past = np.concatenate((z_past, zmulti_past), axis=1)\n",
    "\n",
    "                yz_past = np.concatenate((y_past, z_past), axis=1)  # past without x\n",
    "                xyz_past = np.concatenate((x_past, yz_past), axis=1)  # all past\n",
    "                reduced_model = np.concatenate((y_present, yz_past), axis=1)  # past without x and current y value\n",
    "                full_model = np.concatenate((xyz_past, y_present), axis=1)  # x, y, z's past and current y value\n",
    "\n",
    "                print(z_past.shape, yz_past.shape, xyz_past.shape, reduced_model.shape, full_model.shape)\n",
    "                \n",
    "                # Covariances\n",
    "                entr_reduced = entr(reduced_model.T) - entr(yz_past.T)\n",
    "                entr_full = entr(full_model.T) - entr(xyz_past.T)\n",
    "                \n",
    "                # residual sum of squares\n",
    "                RSS_reduced = np.exp(entr_reduced) # (n_timesteps - (n_rois - 1) * n_lags) * sigma_reduced\n",
    "                RSS_full = np.exp(entr_full) # (n_timesteps - n_rois * n_lags) * sigma_full\n",
    "                \n",
    "                sigma_reduced = RSS_reduced / (n_timesteps - (n_rois - 1) * n_lags)\n",
    "                sigma_full = RSS_full / (n_timesteps - n_rois * n_lags) \n",
    "                \n",
    "                GC_xy = math.log(sigma_reduced / sigma_full) # GC value\n",
    "                GC[i, j] = GC_xy\n",
    "\n",
    "                F_xy = (n_timesteps - (n_dof + len(Z) + 1)*n_lags - 1) / n_lags * (RSS_reduced - RSS_full) / RSS_full\n",
    "                Fstat[i, j] = F_xy\n",
    "\n",
    "                if F_xy > threshold_F:\n",
    "                    GC_sig[i, j] = GC_xy\n",
    "\n",
    "    if verbose:\n",
    "        print(\"F statistics:\", Fstat)\n",
    "        print(\"F threshold:\", threshold_F)\n",
    "        print(\"Significant GC values:\", GC)\n",
    "\n",
    "    return GC_sig, GC, Fstat, threshold_F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1fe665d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bivariateLinearCausalityTE(signals, n_lags=3, pval=0.01, tau=1, verbose=False):\n",
    "    \"\"\" Calculate the bivariate Granger causality between each pair of signals.\n",
    "    cov([...]) --> symmetric square matrix (cov between each pair of elements)\n",
    "    determinant of cov = generalized variance: measure of multi-dimensional scatter (scalar value) / linked to\n",
    "    differential entropy -->  the determinant is nonzero if and only if the matrix  is invertible, and the linear map\n",
    "    represented by the matrix is an isomorphism. det is zero if and only if the column vectors (or the row vectors) of\n",
    "    the matrix are linearly dependent.\n",
    "    see slide 32 of GC presentation\n",
    "    Fstat ~ F(n_lags, n_timesteps - 2*n_lags)\n",
    "\n",
    "    Numpy cov input matrix: each row of m represents a variable, and each column a single observation\n",
    "    Matlab cov input matrix: each row is an observation, and each column a variable\n",
    "\n",
    "    :param signals: variables in rows and observations in columns --> shape = n_rois x n_timesteps (/!\\ Matlab opposite)\n",
    "    :param n_lags: number of past time steps to include in model (order)\n",
    "    :param pval: significance level for the F test. The lower it is, the higher threshold_F (does not change GC)\n",
    "    :param tau: number of time steps between lags --> keep past values at times: [t-tau*i for i in range(n_lags)]\n",
    "           (tau=1 for GC: keep all values up to n_lags, don't skip any)\n",
    "    :param verbose: set to True to display result and threshold\n",
    "\n",
    "    :return GC_sig: significant values of Granger causality matrix\n",
    "    :return GC: Granger causality matrix\n",
    "    :return F_stat: F statistics of the GC test\n",
    "    :return threshold_F: threshold for significance.\n",
    "    \"\"\"\n",
    "    (n_rois, n_timesteps) = signals.shape\n",
    "    n_pairs = n_rois * (n_rois - 1)\n",
    "    # From Fstat definition: F_gc ~ F(n_lags, n_timesteps - 2*n_lags)\n",
    "    # threshold_F = stats.f.ppf(1 - pval / n_pairs, n_lags, n_timesteps - 2 * n_lags)  # statistical threshold\n",
    "    threshold_F = stats.f.ppf(1 - pval / n_pairs, n_lags, n_timesteps - 3 * n_lags - 1)  # statistical threshold\n",
    "    # Bonferroni corrected 1 - pval/n_pairs instead of 1 - pval: n_pairs = number of hypotheses tested,\n",
    "    # pval = significance level\n",
    "\n",
    "    # In stattools gc:\n",
    "    # threshold_F = stats.f.sf\n",
    "    # cdf(F-function, dfn, dfd): Cumulative distribution function. proba that the variable is LESS than or equal to x\n",
    "    # sf(F-function, dfn, dfd): Survival function (also defined as 1 - cdf, but sf is sometimes more accurate). also\n",
    "    # called reliability function --> probability that the variate takes a value GREATER than x\n",
    "    # ppf(desired pval, dfn, dfd): Percent point function (inverse of cdf -> percentiles) --> for a distribution\n",
    "    # function we calculate the probability that the variable is LESS than or equal to x for a given x\n",
    "\n",
    "    # signals = signal.detrend(signals)  # removes the linear trend from each signal: makes the data stationary\n",
    "    # signals = normalisa(signals)  # Matlab normalisa: mean=0, std=1 for each ROI\n",
    "    # normalization is useless: it does not change GC nor Fstat results\n",
    "    # detrend --> slightly different GC & Fstat\n",
    "\n",
    "    Fstat = np.zeros((n_rois, n_rois))  # matrix of all F_xy\n",
    "    GC = np.zeros((n_rois, n_rois))  # matrix of all GC_xy\n",
    "    GC_sig = np.zeros((n_rois, n_rois))  # matrix of all significant GC_xy (if F_xy >= threshold_F)\n",
    "\n",
    "    signals_lagged = lag_signals(signals, n_lags + 1, tau=1)  # n_lags+1 --> n_lags + present\n",
    "\n",
    "    for i, x in enumerate(signals):  # for each column (each roi)\n",
    "        x_lagged = signals_lagged[i]\n",
    "        x_past = x_lagged[:, :-1]  # past of signal x (lagged)\n",
    "\n",
    "        for j, y in enumerate(signals):\n",
    "            if i != j:\n",
    "                y_lagged = signals_lagged[j]\n",
    "                y_present = np.expand_dims(y_lagged[:, -1], axis=1)  # current value of signal y (lagged)\n",
    "                y_past = y_lagged[:, :-1]  # past of signal y (lagged)\n",
    "                xy_past = np.concatenate((x_past, y_past), axis=1)  # both past concatenated\n",
    "                reduced_model = np.concatenate((y_past, y_present), axis=1)  # y's past and current value\n",
    "                full_model = np.concatenate((xy_past, y_present), axis=1)  # x and y's past and current y value\n",
    "\n",
    "                # Covariances\n",
    "                entr_reduced = entr(reduced_model.T) - entr(y_past.T)\n",
    "                entr_full = entr(full_model.T) - entr(xy_past.T)\n",
    "                # FRITES: compute entropy using the slogdet in numpy rather than np.linalg.det\n",
    "                #         nb: the entropy is the logdet ***\n",
    "                \"\"\"\n",
    "                sigma_reduced = np.linalg.det(np.cov(reduced_model.T)) / np.linalg.det(np.cov(y_past.T))\n",
    "                sigma_full = np.linalg.det(np.cov(full_model.T)) / np.linalg.det(np.cov(xy_past.T))\n",
    "                Because the log is used: subtract instead of dividing\n",
    "                \"\"\"\n",
    "#                 sigma_reduced = np.exp(entr_reduced)\n",
    "#                 sigma_full = np.exp(entr_full)\n",
    "\n",
    "#                 GC_xy = (entr_reduced - entr_full)  # GC value = np.log(sigma_reduced / sigma_full) NO 0.5\n",
    "#                 GC[i, j] = GC_xy\n",
    "\n",
    "#                 # residual sum of squares\n",
    "#                 RSS_reduced = (n_timesteps - n_lags) * sigma_reduced\n",
    "#                 RSS_full = (n_timesteps - 2 * n_lags) * sigma_full\n",
    "                \n",
    "                \n",
    "                # residual sum of squares\n",
    "                RSS_reduced = np.exp(entr_reduced) # (n_timesteps -  n_lags) * sigma_reduced\n",
    "                RSS_full = np.exp(entr_full) # (n_timesteps - 2 * n_lags) * sigma_full\n",
    "                \n",
    "                sigma_reduced = RSS_reduced / (n_timesteps - n_lags)\n",
    "                sigma_full = RSS_full / (n_timesteps - 2 * n_lags) \n",
    "                \n",
    "                GC_xy = math.log(sigma_reduced / sigma_full) # GC value\n",
    "                GC[i, j] = GC_xy\n",
    "                \n",
    "                F_xy = (n_timesteps - 3 * n_lags - 1) / n_lags * (RSS_reduced - RSS_full) / RSS_full\n",
    "                Fstat[i, j] = F_xy\n",
    "\n",
    "                if F_xy > threshold_F:\n",
    "                    GC_sig[i, j] = GC_xy\n",
    "\n",
    "    if verbose:\n",
    "        print(\"F statistics:\", Fstat)\n",
    "        print(\"F threshold:\", threshold_F)\n",
    "        print(\"Significant GC values:\", GC)\n",
    "\n",
    "    return GC_sig, GC, Fstat, threshold_F\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def multivariateLinearCausalityTE(signals, n_lags=3, pval=0.01, tau=1, verbose=False):\n",
    "    \"\"\" Calculate the multivariate Granger causality between each pair of signals.\n",
    "    cov([...]) --> symmetric square matrix (cov between each pair of elements)\n",
    "    determinant of cov = generalized variance: measure of multi-dimensional scatter (scalar value) / linked to\n",
    "    differential entropy -->  the determinant is nonzero if and only if the matrix  is invertible, and the linear map\n",
    "    represented by the matrix is an isomorphism. det is zero if and only if the column vectors (or the row vectors) of\n",
    "    the matrix are linearly dependent.\n",
    "    see slide 32 of GC presentation\n",
    "    Fstat ~ F(n_lags, n_timesteps - 2*n_lags)\n",
    "\n",
    "    Numpy cov input matrix: each row of m represents a variable, and each column a single observation\n",
    "    Matlab cov input matrix: each row is an observation, and each column a variable\n",
    "\n",
    "    :param signals: variables in rows and observations in columns --> shape = n_rois x n_timesteps (/!\\ Matlab opposite)\n",
    "    :param n_lags: number of past time steps to include in model (order)\n",
    "    :param pval: significance level for the F test. The lower it is, the higher threshold_F (does not change GC)\n",
    "    :param tau: number of time steps between lags --> keep past values at times: [t-tau*i for i in range(n_lags)]\n",
    "           (tau=1 for GC: keep all values up to n_lags, don't skip any)\n",
    "    :param verbose: set to True to display result and threshold\n",
    "\n",
    "    :return GC_sig: significant values of Granger causality matrix\n",
    "    :return GC: Granger causality matrix\n",
    "    :return F_stat: F statistics of the GC test\n",
    "    :return threshold_F: threshold for significance.\n",
    "    \"\"\"\n",
    "    (n_rois, n_timesteps) = signals.shape\n",
    "    n_pairs = n_rois * (n_rois - 1)\n",
    "    # From Fstat definition: F_gc ~ F(n_lags, n_timesteps - n_rois*n_lags)\n",
    "    # threshold_F = stats.f.ppf(1 - pval / n_pairs, n_lags, n_timesteps - n_rois * n_lags)  # statistical threshold\n",
    "    threshold_F = stats.f.ppf(1 - pval / n_pairs, n_lags, n_timesteps - (n_rois+1) * n_lags - 1)  # statistical threshold \n",
    "    \n",
    "    # Bonferroni corrected 1 - pval/n_pairs instead of 1 - pval: n_pairs = number of hypotheses tested,\n",
    "    # pval = significance level\n",
    "\n",
    "    # In stattools gc:\n",
    "    # threshold_F = stats.f.sf\n",
    "    # cdf(F-function, dfn, dfd): Cumulative distribution function. proba that the variable is LESS than or equal to x\n",
    "    # sf(F-function, dfn, dfd): Survival function (also defined as 1 - cdf, but sf is sometimes more accurate). also\n",
    "    # called reliability function --> probability that the variate takes a value GREATER than x\n",
    "    # ppf(desired pval, dfn, dfd): Percent point function (inverse of cdf -> percentiles) --> for a distribution\n",
    "    # function we calculate the probability that the variable is LESS than or equal to x for a given x\n",
    "\n",
    "    # signals = signal.detrend(signals)  # removes the linear trend from each signal: makes the data stationary\n",
    "    # signals = normalisa(signals)  # Matlab normalisa: mean=0, std=1 for each ROI\n",
    "    # normalization is useless: it does not change GC nor Fstat results\n",
    "    # detrend --> slightly different GC & Fstat\n",
    "\n",
    "    Fstat = np.zeros((n_rois, n_rois))  # matrix of all F_xy\n",
    "    GC = np.zeros((n_rois, n_rois))  # matrix of all GC_xy\n",
    "    GC_sig = np.zeros((n_rois, n_rois))  # matrix of all significant GC_xy (if F_xy >= threshold_F)\n",
    "\n",
    "    signals_lagged = lag_signals(signals, n_lags + 1, tau=1)  # n_lags+1 --> n_lags + present\n",
    "    \n",
    "    for i, x in enumerate(signals):  # for each column (each roi)\n",
    "        x_lagged = signals_lagged[i]\n",
    "        x_past = x_lagged[:, :-1]  # past of signal x (lagged)\n",
    "\n",
    "        for j, y in enumerate(signals):\n",
    "            if i != j:\n",
    "                y_lagged = signals_lagged[j]\n",
    "                y_present = np.expand_dims(y_lagged[:, -1], axis=1)  # current value of signal y (lagged)\n",
    "                y_past = y_lagged[:, :-1]  # past of signal y (lagged)\n",
    "                \n",
    "                small = min(i, j)\n",
    "                large = max(i, j)\n",
    "                z_indices = np.r_[0:small, small + 1:large, large + 1:n_rois]\n",
    "                # OR z_indices = [k for k in range(n_rois) if k not in [i, j]]\n",
    "                z_lagged = signals_lagged[z_indices]\n",
    "                z_past = np.concatenate(z_lagged[:, :, :-1], axis=1)\n",
    "\n",
    "                yz_past = np.concatenate((y_past, z_past), axis=1)  # past without x\n",
    "                xyz_past = np.concatenate((x_past, yz_past), axis=1)  # all past\n",
    "                reduced_model = np.concatenate((y_present, yz_past), axis=1)  # past without x and current y value\n",
    "                full_model = np.concatenate((xyz_past, y_present), axis=1)  # x, y, z's past and current y value\n",
    "\n",
    "                # Covariances\n",
    "                entr_reduced = entr(reduced_model.T) - entr(yz_past.T)\n",
    "                entr_full = entr(full_model.T) - entr(xyz_past.T)\n",
    "\n",
    "                # FRITES: compute entropy using the slogdet in numpy rather than np.linalg.det\n",
    "                #         nb: the entropy is the logdet ***\n",
    "                \"\"\"\n",
    "                sigma_reduced = np.linalg.det(np.cov(reduced_model.T)) / np.linalg.det(np.cov(y_past.T))\n",
    "                sigma_full = np.linalg.det(np.cov(full_model.T)) / np.linalg.det(np.cov(xy_past.T))\n",
    "                Because the log is used: subtract instead of dividing\n",
    "                \"\"\"\n",
    "#                 sigma_reduced = np.exp(entr_reduced)\n",
    "#                 sigma_full = np.exp(entr_full)\n",
    "#                       --> NO RSS is the exp of the entropy. {entropy is biased --> RSS biased} ??\n",
    "#                           sigma = true pop\n",
    "                \n",
    "                # residual sum of squares\n",
    "                RSS_reduced = np.exp(entr_reduced) # (n_timesteps - (n_rois - 1) * n_lags) * sigma_reduced\n",
    "                RSS_full = np.exp(entr_full) # (n_timesteps - n_rois * n_lags) * sigma_full\n",
    "                \n",
    "                sigma_reduced = RSS_reduced / (n_timesteps - (n_rois - 1) * n_lags)\n",
    "                sigma_full = RSS_full / (n_timesteps - n_rois * n_lags) \n",
    "                \n",
    "                GC_xy = math.log(sigma_reduced / sigma_full) # GC value\n",
    "                GC[i, j] = GC_xy\n",
    "                \n",
    "                # F_xy = (n_timesteps - n_rois * n_lags) / n_lags * (RSS_reduced - RSS_full) / RSS_full\n",
    "                F_xy = (n_timesteps - (n_rois+1) * n_lags - 1) / n_lags * (RSS_reduced - RSS_full) / RSS_full\n",
    "                Fstat[i, j] = F_xy\n",
    "\n",
    "                if F_xy > threshold_F:\n",
    "                    GC_sig[i, j] = GC_xy\n",
    "\n",
    "    if verbose:\n",
    "        print(\"F statistics:\", Fstat)\n",
    "        print(\"F threshold:\", threshold_F)\n",
    "        print(\"Significant GC values:\", GC)\n",
    "\n",
    "    return GC_sig, GC, Fstat, threshold_F\n",
    "\n",
    "\n",
    "def lag_signals(signals, n_lags, tau=1):\n",
    "    \"\"\" Create matrix of lagged data sequence signal (lag embedding). Creates a matrix of dimension n_lags and tau lags.\n",
    "    :param signals: matrix of the signals to be embedded\n",
    "    :param n_lags: embedding dimension = np.shape(embedded_signal, 2)\n",
    "    :param tau: number of lags for the embedding (keep tau=1 for GC)\n",
    "    :return signals_lagged: matrix of embedded signals (shape: (n_rois, n_timesteps + tau - n_lags*tau, embed_dim))\n",
    "    \"\"\"\n",
    "    (n_rois, n_timesteps) = np.shape(signals)\n",
    "    signals_lagged = np.zeros((n_rois, n_timesteps + tau - n_lags * tau, n_lags))\n",
    "\n",
    "    for i, x in enumerate(signals):\n",
    "        signals_lagged[i] = np.array([x[np.arange(0, n_timesteps, tau)[:n_lags] + i]\n",
    "                                        for i in range(n_timesteps + tau - n_lags * tau)])\n",
    "    return signals_lagged\n",
    "\n",
    "\n",
    "\n",
    "def entr(xy):\n",
    "    \"\"\"Entropy of a gaussian variable.\n",
    "    This function computes the entropy of a gaussian variable for a 2D input.\n",
    "    \"\"\"\n",
    "    # manually compute the covariance (faster)\n",
    "    n_r, n_c = xy.shape\n",
    "    xy = xy - xy.mean(axis=1, keepdims=True)\n",
    "    out = np.empty((n_r, n_r), xy.dtype, order='C')\n",
    "    np.dot(xy, xy.T, out=out)\n",
    "    out /= (n_c - 1)\n",
    "    # compute entropy using the slogdet in numpy rather than np.linalg.det\n",
    "    # nb: the entropy is the logdet\n",
    "    (sign, h) = np.linalg.slogdet(out)\n",
    "    if not sign > 0:\n",
    "        raise ValueError(f\"Can't estimate the entropy properly of the input \"\n",
    "                         f\"matrix of shape {xy.shape}. Try to increase the \"\n",
    "                         \"step\")\n",
    "    return h\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
