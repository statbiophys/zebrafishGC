{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b816c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run common_functions.ipynb\n",
    "%run plotting_functions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba29a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats \n",
    "from scipy.io import loadmat, savemat\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy.stats import zscore, pearsonr\n",
    "import h5py\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85796b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data_hindbrain/'\n",
    "with open(data_path + 'df_F6T07.pkl', 'rb') as pickle_in:\n",
    "    df_F6T07 = pickle.load(pickle_in)  \n",
    "\n",
    "\n",
    "pval = 0.01\n",
    "\n",
    "n_lags = 3  # number of lags for GC\n",
    "background = df_F6T07.background  # background for plotting\n",
    "\n",
    "cell_centers = df_F6T07.cell_centers  # position of cells on the background\n",
    "n_cells = len(cell_centers)  # number of cells\n",
    "n_pairs = n_cells * (n_cells - 1)\n",
    "\n",
    "swim_neurons = df_F6T07.swim_neurons  # index of motor-correlated neurons\n",
    "n_cells_swim = len(swim_neurons)  # number of motor-correlated neurons\n",
    "n_pairs_swim = n_cells_swim * (n_cells_swim - 1)\n",
    "\n",
    "medial_neurons = df_F6T07.small_rect_neurons  # index of motor-correlated neurons in the medial region\n",
    "n_cells_med = len(medial_neurons)  # number of motor-correlated neurons in the medial region\n",
    "n_pairs_med = n_cells_med * (n_cells_med - 1)\n",
    "\n",
    "fish = 6\n",
    "trace = '07'\n",
    "t_cycles = [round(5.81*(5+i*15)) for i in range(20)]  # start times of stimulus epochs\n",
    "\n",
    "n_timesteps = t_cycles[-1] - t_cycles[0]  # 1656 timesteps corresponding to the 19 stimulus epochs\n",
    "                                          # not 1744 that is the length of the whole recording\n",
    "                                          # we keep 1656 for original GC to be coherent with shuffled GC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2325876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BVGC\n",
    "dfn = n_lags\n",
    "dfd_BV = n_timesteps - 3 * n_lags - 1  # 2 cells involved + 1\n",
    "\n",
    "# For other GCs\n",
    "# dfd_cBV = n_timesteps - 4 * n_lags - 1  # 2 cells involved + stimulus + 1\n",
    "# dfd_MV = n_timesteps - (n_cells_med + 1) * n_lags - 1  # n_cells_med involved +1\n",
    "# dfd_cMV = n_timesteps - (n_cells_med + 2) * n_lags - 1  # n_cells_med involved + stimulus + 1\n",
    "\n",
    "threshold_F_ori = stats.f.ppf(1 - pval/n_pairs_med, dfn, dfd_BV) # Bonferroni corrected, common for all pairs\n",
    "\n",
    "signals = df_F6T07.fzscored[t_cycles[0]:t_cycles[-1]]  # only use 1656 timesteps\n",
    "\n",
    "nmc = 1000  # number of random shuffles - 100 should be enough\n",
    "\n",
    "all_gcs_sh = np.zeros([n_cells_med, n_cells_med, nmc])  # GC matrices for each shuffle\n",
    "all_fstats_sh = np.zeros([n_cells_med, n_cells_med, nmc])  # Fstats matrices for each shuffle\n",
    "gc = np.zeros([n_cells_med, n_cells_med])  # original GC matrix\n",
    "fstats = np.zeros([n_cells_med, n_cells_med])  # original Fstats matrix\n",
    "\n",
    "for i, neuron1 in enumerate(medial_neurons):\n",
    "    for j, neuron2 in enumerate(medial_neurons):\n",
    "        if i != j: \n",
    "            # original GC analysis\n",
    "            # /!\\ NB: threshold_F is not Bonferroni corrected /!\\ (but not used here)\n",
    "            # GC_sig, GC, Fstat, threshold_F = bvgc(...)\n",
    "            _, GC, Fstat, _ = bvgc(signal1, signal2, n_lags=n_lags, pval=0.01, tau=1, verbose=False)\n",
    "            gc[i][j] = GC\n",
    "            fstats[i][j] = Fstat\n",
    "            \n",
    "            # Shuffle nmc times            \n",
    "            for n in range(nmc):\n",
    "                # BVGC\n",
    "                signal1 = shuffle_signal(signals[neuron1], t_cycles)  # shuffle driving signal\n",
    "                signal2 = signals[neuron2][t_cycles[0]:t_cycles[-1]]\n",
    "                _, GC, Fstat, _ = bvgc(signal1, signal2, n_lags=n_lags, pval=0.01, tau=1, verbose=False)\n",
    "\n",
    "                all_gcs_sh[i][j][n] = GC\n",
    "                all_fstats_sh[i][j][n] = Fstat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d490e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale\n",
    "mean_F_sh = np.mean(all_fstats_sh, axis=2)\n",
    "\n",
    "all_fstats_sh_rescaled = np.zeros([n_cells_med, n_cells_med, nmc])\n",
    "all_fstats_sh_rescaled = all_fstats_sh / mean_F_sh  # follows F distribution\n",
    "\n",
    "\n",
    "\n",
    "# customized threshold\n",
    "threshold_F_new = mean_F_sh * threshold_F_ori\n",
    "fstats_normalized = fstats / threshold_F_new\n",
    "\n",
    "# normalized GC\n",
    "GC_sig_new_thresh = np.zeros([n_cells_med, n_cells_med]) # normalized\n",
    "\n",
    "\n",
    "# For hindbrain:\n",
    "#     t_regr = n_timesteps - n_lags = 1653 because 1656 timesteps taken not 1744\n",
    "#     BVGC\n",
    "#         dof_full = 2 * n_lags = 6\n",
    "#         dof_reduced = n_lags = 3\n",
    "#     cBVGC\n",
    "#         dof_full = 3 * n_lags = 9\n",
    "#         dof_reduced = 2 * n_lags = 6\n",
    "#     MVGC\n",
    "#         dof_full = n_rois * n_lags = 60\n",
    "#         dof_reduced = (n_rois - 1) * n_lags = 57\n",
    "#     cMVGC\n",
    "#         dof_full =  (n_rois + 1) * n_lags = 63\n",
    "#         dof_reduced = n_rois * n_lags = 60\n",
    "    \n",
    "for i in range(n_cells_med):\n",
    "    for j in range(n_cells_med):\n",
    "        if fstats[i,j] > threshold_F_new[i,j]:\n",
    "            normalized_GC_sig_new_thresh[i,j] = get_GC_from_Fstat(fstats_normalized[i,j], 2*n_lags, n_lags, t_regr)\n",
    "        else:\n",
    "            normalized_GC_sig_new_thresh[i,j] = np.nan\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyGC-env",
   "language": "python",
   "name": "pygc-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
